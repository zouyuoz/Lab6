{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b10c90",
   "metadata": {},
   "source": [
    "# 2025 DL Lab6: Text Summarization with Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca5a614",
   "metadata": {},
   "source": [
    "**Your Answer:**    \n",
    "Hi I'm 邱照元, 314834001."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1d9c6",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This assignment involves implementing a hybrid sequence-to-sequence model to perform text summarization on the SAMSum and Reddit TIFU datasets.\n",
    "\n",
    "The model architecture is composed of two main parts:\n",
    "A pre-trained model utilized as the encoder.\n",
    "A new decoder which must be implemented from scratch.\n",
    "\n",
    "The objective is to fine-tune the existing encoder while training the custom decoder from the beginning, enabling the complete model to generate accurate and concise summaries. Performance is measured using the standard summarization metric: ROUGE-L Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76750bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Lab6/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.8.0+cu129\n",
      "Python Major.Minor: 3.12\n",
      "transformers version: 4.57.3\n",
      "ABI: True\n",
      "Flash Attention version: 2.8.3\n",
      "Is CUDA available: True\n",
      "CUDA Version: 12.9\n",
      "Device Name: NVIDIA GeForce RTX 5090\n",
      "Flash Attention calculation successful.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import flash_attn\n",
    "import transformers\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Python Major.Minor: {sys.version_info.major}.{sys.version_info.minor}\")\n",
    "print(f\"transformers version: {transformers.__version__}\")\n",
    "print(f\"ABI: {torch._C._GLIBCXX_USE_CXX11_ABI}\")\n",
    "print(f\"Flash Attention version: {flash_attn.__version__}\")\n",
    "print(f\"Is CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# 簡單測試 (若無報錯即成功)\n",
    "q = torch.randn(1, 1, 32, 64, device='cuda', dtype=torch.float16)\n",
    "k = torch.randn(1, 1, 32, 64, device='cuda', dtype=torch.float16)\n",
    "v = torch.randn(1, 1, 32, 64, device='cuda', dtype=torch.float16)\n",
    "from flash_attn import flash_attn_func\n",
    "out = flash_attn_func(q, k, v)\n",
    "print(\"Flash Attention calculation successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce78d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Union\n",
    "from data_utils import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from transformer.Const import *\n",
    "from transformer.Models import Seq2SeqModelWithFlashAttn\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "MODE = \"train\"  # set to \"predict\" for inference\n",
    "CHECKPOINT_PATH = Path(\"checkpoints/latest.pt\")\n",
    "BEST_CHECKPOINT_PATH = Path(\"checkpoints/best.pt\")\n",
    "PREDICT_CHECKPOINT = Path(\"checkpoints/best.pt\")\n",
    "TIFU_TEST_PATH = Path(\"dataset/tifu/tifu_test.jsonl\")\n",
    "SAMSUN_TEST_PATH = Path(\"dataset/samsun/test.csv\")\n",
    "PREDICTION_OUTPUT = Path(\"result.csv\")\n",
    "MAX_TARGET_LEN = 512\n",
    "MAX_GENERATION_LEN = MAX_TARGET_LEN\n",
    "TRAIN_EPOCHS = 40\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "GLOBAL_SEED = 42\n",
    "NUM_WORKERS = 4\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d696f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f16bc4",
   "metadata": {},
   "source": [
    "## CREATE DATASET\n",
    "use ConCate dataset to handle multiple datasets situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ce8de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(\n",
    "    path: List[Optional[str]],\n",
    "    tokenizer: PreTrainedTokenizerBase,\n",
    "    require_target: bool = True,\n",
    ") -> Optional[Dataset]:\n",
    "    if all(p is None for p in path):\n",
    "        return None\n",
    "    datasets = []\n",
    "    for p in path:\n",
    "        if p is not None:\n",
    "            dataset = SquadSeq2SeqDataset(\n",
    "                Path(p), tokenizer, max_source_len=MAX_SOURCE_LEN, max_target_len=MAX_TARGET_LEN, require_target=require_target\n",
    "            )\n",
    "            datasets.append(dataset)\n",
    "    print(f\"Built dataset with {sum(len(ds) for ds in datasets)} samples.\")\n",
    "    if len(datasets) == 1:\n",
    "        return datasets[0]\n",
    "    return ConcatDataset(datasets)\n",
    "\n",
    "def build_dataloader(\n",
    "    source: Union[Optional[Dataset], Optional[str]],\n",
    "    batch_size: int = 4,\n",
    "    shuffle: bool = False,\n",
    "    num_workers: int = 8,\n",
    ") -> Optional[DataLoader]:\n",
    "    dataset = source\n",
    "    collator = QACollator # Don't forget to define QACollator in data_utils.py\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=collator,\n",
    "        num_workers=num_workers,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b937d6",
   "metadata": {},
   "source": [
    "## Main loop of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b1f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(\n",
    "    dataloader: DataLoader,\n",
    "    model: Seq2SeqModelWithFlashAttn,\n",
    "    device: torch.device,\n",
    "    optimizer: Optional[torch.optim.Optimizer],\n",
    "    scheduler: Optional[object],\n",
    "    pad_id: int,\n",
    "    max_grad_norm: float,\n",
    "    train: bool,\n",
    ") -> float:\n",
    "    model.train(train)\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "    iterator = tqdm(dataloader, desc=\"train\" if train else \"eval\", leave=False)\n",
    "    \n",
    "    for batch in iterator:\n",
    "        # 注意：這裡的 src 和 tgt 都是 1D 的 Packed Tensor\n",
    "        src = batch[\"src\"].to(device) # (Total_Src_Tokens,)\n",
    "        tgt = batch[\"tgt\"].to(device) # (Total_Tgt_Tokens,)\n",
    "        src_len = batch[\"src_len\"].to(device) # (B,)\n",
    "        tgt_len = batch[\"tgt_len\"].to(device) # (B,)\n",
    "\n",
    "        ############### YOUR CODE HERE (FLASH ATTENTION VERSION) ###############\n",
    "        \n",
    "        # 因為 tgt 是多個句子串接在一起的 (Packed)，我們不能直接用 [:, :-1] 切片\n",
    "        # 我們需要利用 cumsum 找出每個句子的邊界\n",
    "        \n",
    "        # 1. 計算累積長度來找出每個句子的邊界\n",
    "        cu_len = torch.cumsum(tgt_len, dim=0, dtype=torch.long)\n",
    "        \n",
    "        # 找出每個句子最後一個 Token (EOS) 的位置 -> 用於 Decoder Input (要移除)\n",
    "        end_indices = cu_len - 1\n",
    "        \n",
    "        # 找出每個句子第一個 Token (BOS) 的位置 -> 用於 Labels (要移除)\n",
    "        start_indices = cu_len - tgt_len\n",
    "        \n",
    "        # 2. 製作 Mask 並切片\n",
    "        total_tokens = tgt.size(0)\n",
    "        \n",
    "        # 製作 Decoder Input: 保留所有 token，但移除每個句子的最後一個 token (EOS)\n",
    "        mask_in = torch.ones(total_tokens, dtype=torch.bool, device=device)\n",
    "        mask_in[end_indices] = False\n",
    "        dec_in = tgt[mask_in]\n",
    "        \n",
    "        # 製作 Labels: 保留所有 token，但移除每個句子的第一個 token (BOS)\n",
    "        mask_label = torch.ones(total_tokens, dtype=torch.bool, device=device)\n",
    "        mask_label[start_indices] = False\n",
    "        labels = tgt[mask_label]\n",
    "        \n",
    "        # 調整長度 (每個句子都少了一個 token)\n",
    "        dec_len = tgt_len - 1\n",
    "\n",
    "        # 3. Forward Pass\n",
    "        logits = model(\n",
    "            src_input_ids=src,\n",
    "            trg_input_ids=dec_in,\n",
    "            src_seq_len=src_len,\n",
    "            trg_seq_len=dec_len\n",
    "        )\n",
    "\n",
    "        # 4. Compute Loss\n",
    "        # logits: (Total_Tokens, Vocab_Size), labels: (Total_Tokens,)\n",
    "        # 直接計算 CrossEntropy，不需要再 reshape\n",
    "        loss = F.cross_entropy(logits, labels, ignore_index=pad_id)\n",
    "        \n",
    "        ######################################################\n",
    "        \n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "        steps += 1\n",
    "        iterator.set_postfix(loss=total_loss / max(1, steps))\n",
    "        \n",
    "    return total_loss / max(1, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c1705",
   "metadata": {},
   "source": [
    "## Checkpoints management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f457f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(\n",
    "    model: Seq2SeqModelWithFlashAttn,\n",
    "    path: Path,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "    state = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(state[\"model_state_dict\"])\n",
    "\n",
    "def save_checkpoint(\n",
    "    model: Seq2SeqModelWithFlashAttn,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: Optional[object],\n",
    "    path: Path,\n",
    "    epoch: int,\n",
    ") -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    state = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }\n",
    "    if scheduler is not None and hasattr(scheduler, \"state_dict\"):\n",
    "        state[\"scheduler_state_dict\"] = scheduler.state_dict()\n",
    "    torch.save(state, path)\n",
    "\n",
    "# (選用) 如果你要繼續訓練，建議改用這個版本來同時載入 Optimizer\n",
    "def load_checkpoint_for_training(\n",
    "    model, optimizer, scheduler, path, device\n",
    "):\n",
    "    state = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(state[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer_state_dict\"])\n",
    "    if scheduler is not None and \"scheduler_state_dict\" in state:\n",
    "        scheduler.load_state_dict(state[\"scheduler_state_dict\"])\n",
    "    print(f\"已載入 Epoch {state['epoch']} 的完整訓練狀態\")\n",
    "    return state[\"epoch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079efad",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5cccc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters and arguments ###\n",
    "lr = 2e-4\n",
    "weight_decay = 0.001\n",
    "warmup_steps = 1024\n",
    "epochs = TRAIN_EPOCHS\n",
    "max_grad_norm = 1.0\n",
    "batch_size = TRAIN_BATCH_SIZE\n",
    "num_workers = NUM_WORKERS\n",
    "#####################################\n",
    "set_seed(GLOBAL_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    raise RuntimeError(\"CUDA is required to run this code.\")\n",
    "\n",
    "# Check if flash attention is available\n",
    "try:\n",
    "    import flash_attn  # noqa: F401\n",
    "except ImportError:\n",
    "    raise ImportError(\"flash_attn is required to run this code.\")\n",
    "\n",
    "model = Seq2SeqModelWithFlashAttn(\n",
    "    transformer_model_path=\"answerdotai/ModernBERT-base\",\n",
    "    freeze_encoder=True,\n",
    ").to(device)\n",
    "tokenizer = model.tokenizer\n",
    "checkpoint_path = CHECKPOINT_PATH\n",
    "best_checkpoint_path = BEST_CHECKPOINT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c39fb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built dataset with 44229 samples.\n",
      "Built dataset with 5030 samples.\n"
     ]
    }
   ],
   "source": [
    "train_set = build_dataset(\n",
    "    [\"dataset/tifu/tifu_train.jsonl\", \"dataset/samsun/train.csv\"],\n",
    "    tokenizer=model.tokenizer,\n",
    ")\n",
    "train_loader = build_dataloader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "val_set = build_dataset(\n",
    "    [\"dataset/tifu/tifu_val.jsonl\", \"dataset/samsun/validation.csv\"],\n",
    "    tokenizer=model.tokenizer,\n",
    ")\n",
    "valid_loader = build_dataloader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=lr, weight_decay=weight_decay\n",
    ")\n",
    "total_steps = epochs * len(train_loader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=min(warmup_steps, total_steps),\n",
    "    num_training_steps=total_steps,\n",
    ")\n",
    "\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529b628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 確保你已經定義了 model 和 device，並引入了 Path\n",
    "# from pathlib import Path\n",
    "# latest_ckpt_path = Path(\"checkpoints/latest__.pt\")\n",
    "# if latest_ckpt_path.exists():\n",
    "#     start_epoch = load_checkpoint_for_training(model, optimizer, scheduler, latest_ckpt_path, device)\n",
    "#     print(f\"成功載入模型權重：{latest_ckpt_path}\")\n",
    "# else:\n",
    "#     print(f\"找不到檔案：{latest_ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32d5d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c08e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 - train loss: 7.9436 | val loss: 6.0969 | ppl: 444.47"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40 - train loss: 5.9317 | val loss: 5.5617 | ppl: 260.27"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40 - train loss: 5.4401 | val loss: 5.2125 | ppl: 183.55"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40 - train loss: 4.9671 | val loss: 4.8359 | ppl: 125.96"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40 - train loss: 4.5415 | val loss: 4.5609 | ppl: 95.67"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40 - train loss: 4.2159 | val loss: 4.3887 | ppl: 80.53"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   8%|▊         | 28/346 [00:04<00:45,  7.04it/s, loss=3.98]"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. 初始化記錄用的 list\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_ppls = []\n",
    "UNFREEZE_EPOCH = 9999\n",
    "\n",
    "best_val_ppl = float(\"inf\")\n",
    "\n",
    "for epoch in range(start_epoch + 1, epochs + 1):\n",
    "\n",
    "    # --- [新增] 動態解凍 Encoder ---\n",
    "    if epoch == UNFREEZE_EPOCH:\n",
    "        if epoch == UNFREEZE_EPOCH: print(f\"\\n[Info] Unfreezing Encoder at epoch {epoch}...\")\n",
    "        # 1. 將 Encoder 的參數設定為需要梯度\n",
    "        for param in model.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # 2. (選用) 如果您希望解凍後 Encoder 使用較小的 Learning Rate，\n",
    "        #    可以在這裡重建 optimizer，或者直接繼續使用原本的 (會繼承目前的 LR)\n",
    "        #    最簡單的做法是甚麼都不用做，Optimizer 會自動開始更新這些變成 requires_grad=True 的參數\n",
    "    # -----------------------------\n",
    "\n",
    "    train_loss = run_epoch(\n",
    "        train_loader,\n",
    "        model,\n",
    "        device,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        tokenizer.pad_token_id,\n",
    "        max_grad_norm,\n",
    "        train=True,\n",
    "    )\n",
    "    \n",
    "    # 2. 記錄 Training Loss\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    msg = f\"Epoch {epoch}/{epochs} - train loss: {train_loss:.4f}\"\n",
    "    current_val_ppl = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_loss = run_epoch(\n",
    "            valid_loader,\n",
    "            model,\n",
    "            device,\n",
    "            optimizer=None,\n",
    "            scheduler=None,\n",
    "            pad_id=tokenizer.pad_token_id,\n",
    "            max_grad_norm=max_grad_norm,\n",
    "            train=False,\n",
    "        )\n",
    "    \n",
    "    perplexity = math.exp(min(20, val_loss))\n",
    "    current_val_ppl = perplexity\n",
    "    \n",
    "    # 3. 記錄 Validation Loss 和 Perplexity\n",
    "    val_losses.append(val_loss)\n",
    "    val_ppls.append(perplexity)\n",
    "\n",
    "    msg += f\" | val loss: {val_loss:.4f} | ppl: {perplexity:.2f}\"\n",
    "    print(msg, end=\"\")\n",
    "    \n",
    "    if checkpoint_path is not None:    \n",
    "        save_checkpoint(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            path=checkpoint_path,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "    if (\n",
    "        current_val_ppl is not None\n",
    "        and current_val_ppl < best_val_ppl\n",
    "        and best_checkpoint_path is not None\n",
    "    ):\n",
    "        best_val_ppl = current_val_ppl\n",
    "        save_checkpoint(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            path=best_checkpoint_path,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "\n",
    "# 4. 訓練結束後，將記錄寫入 CSV\n",
    "timestamp = datetime.now().strftime(\"%m%d%H%M\")\n",
    "log_filename = f\"log_{timestamp}.csv\"\n",
    "\n",
    "try:\n",
    "    with open(log_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # 寫入標頭\n",
    "        writer.writerow([\"train_loss\", \"val_loss\", \"ppl\"])\n",
    "        # 寫入數據\n",
    "        for t, v, p in zip(train_losses, val_losses, val_ppls):\n",
    "            writer.writerow([t, v, p])\n",
    "    print(f\"\\n[Info] Training log successfully saved to {log_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n[Error] Failed to save training log: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acffb21",
   "metadata": {},
   "source": [
    "## Predict Result\n",
    "\n",
    "Predict the labesl based on testing set. Upload to [Kaggle](https://www.kaggle.com/t/69788476947b482b88e46c9565db190b).\n",
    "\n",
    "**How to upload**\n",
    "\n",
    "1. To kaggle. Click \"Submit Predictions\"\n",
    "2. Upload the result.csv\n",
    "3. System will automaticlaly calculate the accuracy of 50% dataset and publish this result to leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0baffe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built dataset with 9248 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "load_checkpoint(model, PREDICT_CHECKPOINT, device)\n",
    "model.eval()\n",
    "test_set = build_dataset(\n",
    "    [TIFU_TEST_PATH, SAMSUN_TEST_PATH],\n",
    "    tokenizer=model.tokenizer,\n",
    "    require_target=False,\n",
    ")\n",
    "test_loader = build_dataloader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "predictions: List[Tuple[str, str]] = []\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(test_loader, desc=\"predict\", leave=False):\n",
    "        input_ids = sample[\"src\"].to(device)\n",
    "        src_lens = sample[\"src_len\"].to(device=device, dtype=torch.int32)\n",
    "        ids = sample[\"id\"] #list of ids\n",
    "        summaries = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            src_seq_len=src_lens,\n",
    "            generation_limit=MAX_GENERATION_LEN,\n",
    "            sampling=True,\n",
    "            top_k=50,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "        predictions.extend(zip(ids, summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a3ed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 9248 predictions to result_11292308.csv\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%m%d%H%M\")\n",
    "output_path = Path(f\"result_{timestamp}.csv\")\n",
    "write_predictions_csv(output_path, predictions)\n",
    "print(f\"Wrote {len(predictions)} predictions to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236bb36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_EPOCHS = 40\n",
      "TRAIN_BATCH_SIZE = 128\n",
      "wARMUP_STEP = 1024\n",
      "LERANING_RATE = 0.0002\n",
      "MAX_SOURCE_LEN = 1800\n",
      "\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/user/.config/kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 1.01M/1.01M [00:01<00:00, 600kB/s]\n",
      "Successfully submitted to Lab6 Text Summarization with Seq2Seq Model(639401)"
     ]
    }
   ],
   "source": [
    "Message = (\"\"\n",
    "    +f\"TRAIN_EPOCHS = {TRAIN_EPOCHS}\\n\"\n",
    "    +f\"TRAIN_BATCH_SIZE = {TRAIN_BATCH_SIZE}\\n\"\n",
    "    +f\"WARMUP_STEP = {warmup_steps}\\n\"\n",
    "    +f\"LERANING_RATE = {lr}\\n\"\n",
    "    +f\"MAX_SOURCE_LEN = {MAX_SOURCE_LEN}\\n\"\n",
    "    +\"d_inner = 768 * 4\\n\"\n",
    ")\n",
    "!echo \"{Message}\"\n",
    "!kaggle competitions submit -c lab-6-training-a-seq-2-seq-model-on-s-qu-ad-639401 -f {output_path} -m \"{Message}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7d794",
   "metadata": {},
   "source": [
    "11282304:\n",
    "TRAIN_EPOCHS = 30\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "LERANING_RATE = 8e-05\n",
    "MAX_SOURCE_LEN = 2048\n",
    "\n",
    "11282345:\n",
    "TRAIN_EPOCHS = 30\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "LERANING_RATE = 8e-05\n",
    "MAX_SOURCE_LEN = 1024\n",
    "\n",
    "11290034:\n",
    "TRAIN_EPOCHS = 30\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "LERANING_RATE = 8e-05\n",
    "MAX_SOURCE_LEN = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b01808",
   "metadata": {},
   "source": [
    "**解決方案**\n",
    "\n",
    "如果您希望使用較大的 Batch Size (如 128 或 256) 並且維持效能，建議您：\n",
    "\n",
    "1. **增加 Epochs**：把 Epochs 增加到 40 或 50，補回失去的 Steps。\n",
    "2. **調大 Learning Rate**：嘗試將 LR 調回 1e-4 甚至 2e-4。\n",
    "3. **減少 Warmup**：將 warmup_steps 設為總步數的 5%~10% (例如 BS=128 時設為 500~1000)。\n",
    "\n",
    "如果要在現有架構上改進，CP 值最高的順序是：\n",
    "\n",
    "1. Decoder 改 Pre-Norm：改幾行程式碼而已，結構更穩。\n",
    "1. 調整 Dimension：把 d_inner 改回 768 * 4。\n",
    "1. Decoder 先 Train：這其實就是您一開始 freeze_encoder=True 的狀態！您可以先跑 5 個 Epoch (Freeze)，然後再跑 25 個 Epoch (Unfreeze)。\n",
    "1. LoRA：這需要引入 peft 套件，改動稍大，但如果是為了比賽衝分，這是必殺技。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
